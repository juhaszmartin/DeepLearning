{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from dateutil import parser as date_parser\n",
    "import uuid\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e1b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This was used in a practical to see overlaps in the 'consensus' folder.\n",
    "\n",
    "# def load_labels(folder=\"./consensus\"):\n",
    "#     \"\"\"Load all label JSONs from a folder, skipping empty or invalid files.\"\"\"\n",
    "#     data = {}\n",
    "#     for fname in os.listdir(folder):\n",
    "#         if not fname.endswith(\".json\"):\n",
    "#             continue\n",
    "#         fpath = os.path.join(folder, fname)\n",
    "#         with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
    "#             content = f.read().strip()\n",
    "#             if not content:\n",
    "#                 print(f\"Skipping empty file: {fname}\")\n",
    "#                 continue\n",
    "#             try:\n",
    "#                 data[fname] = json.loads(content)\n",
    "#             except json.JSONDecodeError as e:\n",
    "#                 print(f\"Skipping invalid JSON in {fname}: {e}\")\n",
    "#                 continue\n",
    "#     return data\n",
    "\n",
    "\n",
    "\n",
    "# def overlap(a, b):\n",
    "#     \"\"\"Return overlap length between two intervals [a_start, a_end], [b_start, b_end].\"\"\"\n",
    "#     return max(0, min(a[\"end\"], b[\"end\"]) - max(a[\"start\"], b[\"start\"]))\n",
    "\n",
    "\n",
    "# def is_same(a, b):\n",
    "#     \"\"\"Check if two intervals are considered 'the same'.\"\"\"\n",
    "#     len_a = a[\"end\"] - a[\"start\"]\n",
    "#     len_b = b[\"end\"] - b[\"start\"]\n",
    "#     ov = overlap(a, b)\n",
    "#     return ov >= 0.5 * min(len_a, len_b)\n",
    "\n",
    "\n",
    "# def flatten_annotations(data):\n",
    "#     \"\"\"\n",
    "#     Flatten Label Studio timeseries JSONs into list of\n",
    "#     {start, end, choices, annotator} entries.\n",
    "#     Converts ISO time strings to numeric timestamps for overlap math.\n",
    "#     \"\"\"\n",
    "#     all_entries = []\n",
    "\n",
    "#     def parse_time(ts):\n",
    "#         # Converts e.g. \"2023-01-10T10:15:00.000Z\" â†’ POSIX timestamp (float seconds)\n",
    "#         try:\n",
    "#             return datetime.fromisoformat(ts.replace(\"Z\", \"+00:00\")).timestamp()\n",
    "#         except Exception:\n",
    "#             return None\n",
    "\n",
    "#     for annotator, tasks in data.items():\n",
    "#         if not isinstance(tasks, list):\n",
    "#             print(f\"Unexpected top-level format in {annotator}, skipping.\")\n",
    "#             continue\n",
    "\n",
    "#         for task in tasks:\n",
    "#             for ann in task.get(\"annotations\", []):\n",
    "#                 user = ann.get(\"completed_by\", annotator)\n",
    "#                 for r in ann.get(\"result\", []):\n",
    "#                     v = r.get(\"value\", {})\n",
    "#                     start = parse_time(v.get(\"start\"))\n",
    "#                     end = parse_time(v.get(\"end\"))\n",
    "#                     choices = v.get(\"timeserieslabels\")\n",
    "\n",
    "#                     if start is None or end is None or not choices:\n",
    "#                         print(f\"Skipping malformed entry in {annotator}: {v}\")\n",
    "#                         continue\n",
    "\n",
    "#                     all_entries.append({\n",
    "#                         \"annotator\": str(user),\n",
    "#                         \"start\": start,\n",
    "#                         \"end\": end,\n",
    "#                         \"choices\": choices\n",
    "#                     })\n",
    "\n",
    "#     print(f\"Flattened {len(all_entries)} total label intervals from {len(data)} files.\")\n",
    "#     return all_entries\n",
    "\n",
    "\n",
    "# def compute_consensus(all_entries):\n",
    "#     \"\"\"Compute consensus per overlapping group using majority vote.\"\"\"\n",
    "#     consensus = []\n",
    "#     used = set()\n",
    "#     for i, a in enumerate(all_entries):\n",
    "#         if i in used:\n",
    "#             continue\n",
    "#         group = [a]\n",
    "#         used.add(i)\n",
    "#         for j, b in enumerate(all_entries):\n",
    "#             if j not in used and is_same(a, b):\n",
    "#                 group.append(b)\n",
    "#                 used.add(j)\n",
    "#         # majority voting for choices\n",
    "#         all_choices = [c for g in group for c in g[\"choices\"]]\n",
    "#         maj = [k for k, v in Counter(all_choices).items() if v == max(Counter(all_choices).values())]\n",
    "#         consensus.append({\n",
    "#             \"start\": min(g[\"start\"] for g in group),\n",
    "#             \"end\": max(g[\"end\"] for g in group),\n",
    "#             \"choices\": maj\n",
    "#         })\n",
    "#     return consensus\n",
    "\n",
    "\n",
    "# def evaluate_accuracy(all_entries, consensus):\n",
    "#     \"\"\"Compare each annotator to consensus.\"\"\"\n",
    "#     stats = defaultdict(lambda: {\"tp\": 0, \"fp\": 0, \"fn\": 0})\n",
    "#     for entry in all_entries:\n",
    "#         ann = entry[\"annotator\"]\n",
    "#         matched = False\n",
    "#         for c in consensus:\n",
    "#             if is_same(entry, c):\n",
    "#                 if any(ch in c[\"choices\"] for ch in entry[\"choices\"]):\n",
    "#                     stats[ann][\"tp\"] += 1\n",
    "#                 else:\n",
    "#                     stats[ann][\"fp\"] += 1\n",
    "#                 matched = True\n",
    "#                 break\n",
    "#         if not matched:\n",
    "#             stats[ann][\"fn\"] += 1\n",
    "#     # compute accuracy\n",
    "#     for ann, s in stats.items():\n",
    "#         denom = s[\"tp\"] + s[\"fp\"] + s[\"fn\"]\n",
    "#         s[\"accuracy\"] = s[\"tp\"] / denom if denom else 0\n",
    "#     return stats\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     data = load_labels(\"./flags/bullflagdetector/consensus\")\n",
    "#     entries = flatten_annotations(data)\n",
    "#     consensus = compute_consensus(entries)\n",
    "#     stats = evaluate_accuracy(entries, consensus)\n",
    "\n",
    "#     print(\"=== Overlap Statistics ===\")\n",
    "\n",
    "#     overlaps_global = []\n",
    "#     overlaps_per_label = defaultdict(list)\n",
    "\n",
    "#     for i, a in enumerate(entries):\n",
    "#         for j, b in enumerate(entries):\n",
    "#             if i >= j:\n",
    "#                 continue\n",
    "#             ov = overlap(a, b)\n",
    "#             if ov <= 0:\n",
    "#                 continue\n",
    "\n",
    "#             min_len = min(a[\"end\"] - a[\"start\"], b[\"end\"] - b[\"start\"])\n",
    "#             percent = 100 * ov / min_len\n",
    "\n",
    "#             # Add to global list\n",
    "#             overlaps_global.append(percent)\n",
    "\n",
    "#             # Add to per-label lists â€” only for shared labels\n",
    "#             common_labels = set(a[\"choices\"]) & set(b[\"choices\"])\n",
    "#             for lbl in common_labels:\n",
    "#                 overlaps_per_label[lbl].append(percent)\n",
    "\n",
    "#     # === Global statistics ===\n",
    "#     if overlaps_global:\n",
    "#         avg_overlap = sum(overlaps_global) / len(overlaps_global)\n",
    "#         print(f\"Average overlap (all labels): {avg_overlap:.2f}%\")\n",
    "#         print(f\"Max overlap: {max(overlaps_global):.2f}%\")\n",
    "#         print(f\"Overlapping pairs: {len(overlaps_global)}\")\n",
    "#     else:\n",
    "#         print(\"No overlaps found.\")\n",
    "\n",
    "#     # === Per-label statistics ===\n",
    "#     print(\"\\n=== Average overlap per label ===\")\n",
    "#     if overlaps_per_label:\n",
    "#         for lbl, vals in sorted(overlaps_per_label.items()):\n",
    "#             avg_lbl = sum(vals) / len(vals)\n",
    "#             print(f\"{lbl:20s}  {avg_lbl:6.2f}%  ({len(vals)} pairs)\")\n",
    "#     else:\n",
    "#         print(\"No label overlaps found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5c0f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"./flags/bullflagdetector\"\n",
    "\n",
    "def to_ms(val):\n",
    "    \"\"\"Robustly converts timestamps to Unix milliseconds (int64).\"\"\"\n",
    "    if val is None or val == \"\":\n",
    "        return None\n",
    "    if isinstance(val, (int, float)):\n",
    "        return int(val)\n",
    "    if isinstance(val, str):\n",
    "        if val.isdigit():\n",
    "            return int(val)\n",
    "        try:\n",
    "            dt = date_parser.parse(val)\n",
    "            return int(dt.timestamp() * 1000)\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def load_all_labels(root_path):\n",
    "    all_segments = []\n",
    "    \n",
    "    # 1. Identify valid folders (skipping consensus/sample)\n",
    "    folders = [f for f in os.listdir(root_path) \n",
    "               if os.path.isdir(os.path.join(root_path, f)) \n",
    "               and f.lower() not in (\"consensus\", \"sample\")]\n",
    "    \n",
    "    print(f\"Processing {len(folders)} student folders for 'timeserieslabels'...\\n\")\n",
    "\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(root_path, folder)\n",
    "        json_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.json')]\n",
    "        \n",
    "        for jf in json_files:\n",
    "            file_path = os.path.join(folder_path, jf)\n",
    "            \n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                # Standardize data to a list of tasks\n",
    "                if isinstance(data, dict):\n",
    "                    data = [data]\n",
    "                \n",
    "                for task in data:\n",
    "                    # --- FORMAT A: Standard Label Studio (annotations -> result -> value) ---\n",
    "                    if 'annotations' in task:\n",
    "                        # Extract CSV name\n",
    "                        csv_name = task.get('data', {}).get('csv') or \\\n",
    "                                   task.get('file_upload') or \\\n",
    "                                   task.get('csv') or \\\n",
    "                                   \"unknown_file.csv\"\n",
    "                        csv_name = os.path.basename(csv_name)\n",
    "\n",
    "                        for ann in task.get('annotations', []):\n",
    "                            for res in ann.get('result', []):\n",
    "                                val = res.get('value', {})\n",
    "                                start_raw = val.get('start')\n",
    "                                end_raw = val.get('end')\n",
    "                                \n",
    "                                # STRICTLY LOOK FOR 'timeserieslabels'\n",
    "                                # Label Studio returns a list, e.g., [\"BearFlag\"]\n",
    "                                label_list = val.get('timeserieslabels')\n",
    "                                \n",
    "                                if label_list and isinstance(label_list, list) and len(label_list) > 0:\n",
    "                                    label_tag = label_list[0]\n",
    "                                else:\n",
    "                                    # If key is missing, mark as Unknown so we can debug\n",
    "                                    label_tag = \"Unknown\" \n",
    "\n",
    "                                if start_raw is not None and end_raw is not None:\n",
    "                                    all_segments.append({\n",
    "                                        'annotator': folder,\n",
    "                                        'json_file': jf,\n",
    "                                        'csv_file': csv_name,\n",
    "                                        'start_raw': start_raw,\n",
    "                                        'start_ms': to_ms(start_raw),\n",
    "                                        'end_ms': to_ms(end_raw),\n",
    "                                        'label': label_tag\n",
    "                                    })\n",
    "\n",
    "                    # --- FORMAT B: Simple Structure (used by TYEGJ8, VWXUD6) ---\n",
    "                    elif 'label' in task and isinstance(task['label'], list):\n",
    "                        csv_name = os.path.basename(task.get('csv', 'unknown_file.csv'))\n",
    "                        \n",
    "                        for lbl in task['label']:\n",
    "                            start_raw = lbl.get('start')\n",
    "                            end_raw = lbl.get('end')\n",
    "                            \n",
    "                            # STRICTLY LOOK FOR 'timeserieslabels' HERE TOO\n",
    "                            label_list = lbl.get('timeserieslabels')\n",
    "                            \n",
    "                            if label_list and isinstance(label_list, list) and len(label_list) > 0:\n",
    "                                label_tag = label_list[0]\n",
    "                            else:\n",
    "                                # Fallback: sometimes these custom formats store label directly as string?\n",
    "                                # If you see \"Unknown\" for these folders, we can inspect 'lbl' keys.\n",
    "                                label_tag = \"Unknown\"\n",
    "\n",
    "                            if start_raw is not None:\n",
    "                                all_segments.append({\n",
    "                                    'annotator': folder,\n",
    "                                    'json_file': jf,\n",
    "                                    'csv_file': csv_name,\n",
    "                                    'start_raw': start_raw,\n",
    "                                    'start_ms': to_ms(start_raw),\n",
    "                                    'end_ms': to_ms(end_raw),\n",
    "                                    'label': label_tag\n",
    "                                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {folder}/{jf}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(all_segments)\n",
    "    return df\n",
    "\n",
    "# --- EXECUTE ---\n",
    "df = load_all_labels(ROOT)\n",
    "\n",
    "if not df.empty:\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Loaded {len(df)} segments.\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Check the labels now\n",
    "    print(\"\\nðŸ“Š Label Counts (Should show Bear/Bull variations):\")\n",
    "    print(df['label'].value_counts())\n",
    "    \n",
    "    # Check if any are still stuck as \"Unknown\"\n",
    "    if 'Unknown' in df['label'].values:\n",
    "        print(\"\\nWarning: Some segments have 'Unknown' labels. Checking source...\")\n",
    "        print(df[df['label'] == 'Unknown'][['annotator', 'json_file']].head())\n",
    "else:\n",
    "    print(\"No segments found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9271869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa25fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "ROOT_DIR = \"./flags/bullflagdetector\"\n",
    "\n",
    "def find_csv_in_folder(target_folder, filename_from_json):\n",
    "    \"\"\"\n",
    "    Searches for a CSV within a specific student folder.\n",
    "    Handles 'Smart Matching' to ignore Label Studio UUID prefixes.\n",
    "    \"\"\"\n",
    "    # 1. Try exact match first\n",
    "    exact_path = os.path.join(target_folder, filename_from_json)\n",
    "    if os.path.exists(exact_path):\n",
    "        return exact_path\n",
    "\n",
    "    # 2. recursive search in student folder (in case of subdirs like 'upload/')\n",
    "    # AND fuzzy match (ignoring UUID prefix)\n",
    "    clean_target_name = filename_from_json\n",
    "    # If the json name has a UUID prefix like \"abc12345-file.csv\", try to strip it\n",
    "    if '-' in clean_target_name and clean_target_name[8] == '-': # Simple heuristic for UUID\n",
    "        clean_target_name = clean_target_name.split('-', 1)[1]\n",
    "\n",
    "    for root, dirs, files in os.walk(target_folder):\n",
    "        for f in files:\n",
    "            # Case A: Exact filename match in subdirectory\n",
    "            if f == filename_from_json:\n",
    "                return os.path.join(root, f)\n",
    "            \n",
    "            # Case B: The file on disk is \"data.csv\" but JSON asks for \"12345-data.csv\"\n",
    "            if filename_from_json.endswith(f) and len(f) > 4:\n",
    "                return os.path.join(root, f)\n",
    "\n",
    "            # Case C: The file on disk has a prefix, or JSON has a prefix (Flexible endswith)\n",
    "            # This handles: JSON=\"uuid-data.csv\" vs Disk=\"data.csv\"\n",
    "            if f.endswith(clean_target_name) or clean_target_name.endswith(f):\n",
    "                 return os.path.join(root, f)\n",
    "                 \n",
    "    return None\n",
    "\n",
    "def build_timeseries_df_local(metadata_df, root_dir):\n",
    "    all_segments_data = []\n",
    "    \n",
    "    # Group by Annotator (Folder) so we look for CSVs in the right place\n",
    "    grouped = metadata_df.groupby('annotator')\n",
    "    \n",
    "    print(f\"Processing {len(grouped)} folders...\\n\")\n",
    "\n",
    "    for annotator, group in grouped:\n",
    "        student_folder = os.path.join(root_dir, annotator)\n",
    "        \n",
    "        # Get unique CSVs this specific student used\n",
    "        student_csvs = group['csv_file'].unique()\n",
    "        \n",
    "        print(f\"{annotator}\")\n",
    "        \n",
    "        for csv_name in student_csvs:\n",
    "            # Locate CSV *specifically* in this student's folder\n",
    "            csv_path = find_csv_in_folder(student_folder, csv_name)\n",
    "            \n",
    "            if not csv_path:\n",
    "                count = len(group[group['csv_file'] == csv_name])\n",
    "                print(f\"   Missing CSV: '{csv_name}' (needed for {count} labels)\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Load CSV\n",
    "                df_raw = pd.read_csv(csv_path, sep=None, engine='python')\n",
    "                \n",
    "                # Standardize Time Column\n",
    "                time_col = [c for c in df_raw.columns if 'time' in c.lower()]\n",
    "                time_col = time_col[0] if time_col else df_raw.columns[0]\n",
    "                \n",
    "                # Robust Time Conversion (to match JSON ms)\n",
    "                try:\n",
    "                    df_raw['_ts_ms'] = pd.to_numeric(df_raw[time_col])\n",
    "                    if df_raw['_ts_ms'].mean() < 2e10: # If seconds, convert to ms\n",
    "                        df_raw['_ts_ms'] = df_raw['_ts_ms'] * 1000\n",
    "                except:\n",
    "                    df_raw['_ts_ms'] = pd.to_datetime(df_raw[time_col], utc=True).astype('int64') // 10**6\n",
    "\n",
    "                # Extract Segments for this specific CSV\n",
    "                # Filter the group to only rows using this specific CSV\n",
    "                csv_labels = group[group['csv_file'] == csv_name]\n",
    "                \n",
    "                extracted_count = 0\n",
    "                for _, row in csv_labels.iterrows():\n",
    "                    start = row['start_ms']\n",
    "                    end = row['end_ms']\n",
    "                    \n",
    "                    # Slice\n",
    "                    mask = (df_raw['_ts_ms'] >= start) & (df_raw['_ts_ms'] <= end)\n",
    "                    segment_slice = df_raw[mask].copy()\n",
    "                    \n",
    "                    if not segment_slice.empty:\n",
    "                        segment_slice['segment_id'] = str(uuid.uuid4())\n",
    "                        segment_slice['label'] = row['label']\n",
    "                        segment_slice['annotator'] = annotator\n",
    "                        segment_slice['original_csv'] = csv_name # useful for debug\n",
    "                        \n",
    "                        # Normalize columns\n",
    "                        segment_slice.rename(columns={time_col: 'timestamp'}, inplace=True)\n",
    "                        segment_slice.columns = [c.lower() for c in segment_slice.columns]\n",
    "                        \n",
    "                        all_segments_data.append(segment_slice)\n",
    "                        extracted_count += 1\n",
    "                \n",
    "                print(f\"   Loaded '{csv_name}' -> {extracted_count} segments\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   Error reading '{csv_name}': {e}\")\n",
    "        \n",
    "        # visual separator between students\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    # Compile Final DataFrame\n",
    "    if all_segments_data:\n",
    "        final_df = pd.concat(all_segments_data, ignore_index=True)\n",
    "        print(f\"\\nDONE! Extracted {len(final_df)} rows across {final_df['segment_id'].nunique()} unique segments.\")\n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"\\nNo data extracted.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- EXECUTE ---\n",
    "# Pass the metadata df from the previous step (load_all_labels)\n",
    "df_timeseries = build_timeseries_df_local(df, ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38befcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timeseries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb8929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Load data if not already in memory\n",
    "# if 'df_timeseries' not in locals():\n",
    "#     try:\n",
    "#         df_timeseries = pd.read_csv(\"all_labeled_timeseries_union.csv\")\n",
    "#     except FileNotFoundError:\n",
    "#         print(\"Dataframe not found. Please run the extraction code first.\")\n",
    "\n",
    "# 2. Settings\n",
    "examples_per_label = 4  # How many charts to show per label\n",
    "unique_labels = df_timeseries['label'].unique()\n",
    "cols_to_plot = 'close'  # Assuming 'close' column exists; change if needed\n",
    "\n",
    "# 3. Setup Plot\n",
    "fig, axes = plt.subplots(nrows=len(unique_labels), ncols=examples_per_label, \n",
    "                         figsize=(16, 3 * len(unique_labels)), constrained_layout=True)\n",
    "\n",
    "# 4. Loop through each label and plot examples\n",
    "for i, label in enumerate(unique_labels):\n",
    "    # Get all unique segment IDs for this specific label\n",
    "    segment_ids = df_timeseries[df_timeseries['label'] == label]['segment_id'].unique()\n",
    "    \n",
    "    # Pick random examples (or use [:examples_per_label] for the first ones)\n",
    "    chosen_ids = random.sample(list(segment_ids), min(len(segment_ids), examples_per_label))\n",
    "    \n",
    "    for j in range(examples_per_label):\n",
    "        # Handle indexing for 1D vs 2D axes array\n",
    "        ax = axes[i, j] if len(unique_labels) > 1 else axes[j]\n",
    "        \n",
    "        if j < len(chosen_ids):\n",
    "            seg_id = chosen_ids[j]\n",
    "            data = df_timeseries[df_timeseries['segment_id'] == seg_id].sort_values('timestamp')\n",
    "            \n",
    "            # Plot the data\n",
    "            ax.plot(data.reset_index(drop=True)[cols_to_plot], color='#1f77b4', linewidth=2)\n",
    "            \n",
    "            # Styling\n",
    "            ax.set_title(f\"{label}\\n(ID: ...{str(seg_id)[-8:]})\", fontsize=9)\n",
    "            ax.grid(True, linestyle=':', alpha=0.6)\n",
    "            ax.set_xticks([]) # Hide x-axis ticks for cleaner look\n",
    "        else:\n",
    "            ax.axis('off') # Hide unused subplots if not enough examples\n",
    "\n",
    "print(f\"Displaying {examples_per_label} examples for each of the {len(unique_labels)} labels...\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29491de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OUTLIER DETECTION & REMOVAL ---\n",
    "\n",
    "# 1. Calculate length of every segment\n",
    "segment_stats = df_timeseries.groupby('segment_id').agg(\n",
    "    length=('close', 'count'),\n",
    "    annotator=('annotator', 'first'),\n",
    "    csv_file=('original_csv', 'first'), # or 'csv_file' depending on your col name\n",
    "    label=('label', 'first')\n",
    ").reset_index()\n",
    "\n",
    "# 2. Define Threshold (e.g., > 500 candles is likely a mistake for a flag)\n",
    "MAX_LEN = 100\n",
    "outliers = segment_stats[segment_stats['length'] > MAX_LEN].sort_values('length', ascending=False)\n",
    "\n",
    "if not outliers.empty:\n",
    "    print(f\"FOUND {len(outliers)} OUTLIER SEGMENTS (Length > {MAX_LEN}):\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Length':<10} {'Annotator':<15} {'Label':<20} {'CSV File'}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for _, row in outliers.iterrows():\n",
    "        print(f\"{row['length']:<10} {row['annotator']:<15} {row['label']:<20} {row['csv_file']}\")\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # 3. Filter them out\n",
    "    outlier_ids = outliers['segment_id'].values\n",
    "    df_clean = df_timeseries[~df_timeseries['segment_id'].isin(outlier_ids)].copy()\n",
    "    \n",
    "    print(f\"\\nCleaned Dataset: {len(df_clean)} rows (was {len(df_timeseries)})\")\n",
    "    \n",
    "else:\n",
    "    print(\"No outliers found. Dataset is clean.\")\n",
    "    df_clean = df_timeseries.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e554b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional: Visualize Outliers\n",
    "# segment_stats = df_timeseries.groupby('segment_id').agg(\n",
    "#     length=('close', 'count'),\n",
    "#     annotator=('annotator', 'first'),\n",
    "#     csv_file=('original_csv', 'first'),\n",
    "#     label=('label', 'first')\n",
    "# ).reset_index()\n",
    "\n",
    "\n",
    "# MAX_LEN = 100\n",
    "# outliers = segment_stats[segment_stats['length'] > MAX_LEN].sort_values('length', ascending=False)\n",
    "\n",
    "\n",
    "# num_plots = len(outliers)\n",
    "# if num_plots > 0:\n",
    "#     print(f\"Plotting {num_plots} outlier segments...\")\n",
    "    \n",
    "#     cols = 2\n",
    "#     rows = math.ceil(num_plots / cols)\n",
    "#     fig, axes = plt.subplots(rows, cols, figsize=(15, 4 * rows), constrained_layout=True)\n",
    "#     axes = axes.flatten() # Flatten 2D array to 1D for easy iteration\n",
    "\n",
    "#     # 3. Loop through outliers and plot\n",
    "#     for i, (_, row) in enumerate(outliers.iterrows()):\n",
    "#         seg_id = row['segment_id']\n",
    "#         annotator = row['annotator']\n",
    "#         length = row['length']\n",
    "#         csv_name = row['csv_file']\n",
    "        \n",
    "#         # Get data for this segment\n",
    "#         data = df_timeseries[df_timeseries['segment_id'] == seg_id].sort_values('timestamp')\n",
    "        \n",
    "#         # Plot\n",
    "#         ax = axes[i]\n",
    "#         ax.plot(data['timestamp'], data['close'], color='red', linewidth=1.5)\n",
    "        \n",
    "#         # Styling\n",
    "#         ax.set_title(f\"User: {annotator} | Len: {length}\\nFile: {csv_name}\", fontsize=10, fontweight='bold')\n",
    "#         ax.grid(True, linestyle=':', alpha=0.6)\n",
    "        \n",
    "#         # Clean up x-axis (too many dates make it unreadable)\n",
    "#         ax.set_xticks([]) \n",
    "#         ax.set_xlabel(\"Time (Hidden)\", fontsize=8)\n",
    "\n",
    "#     # Turn off unused subplots\n",
    "#     for j in range(i + 1, len(axes)):\n",
    "#         axes[j].axis('off')\n",
    "\n",
    "#     plt.show()\n",
    "# else:\n",
    "#     print(\"No outliers to plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique segments and their labels for splitting\n",
    "segment_metadata = df_clean.drop_duplicates(subset=['segment_id'])[['segment_id', 'label']]\n",
    "\n",
    "# Perform Stratified Split on the IDs\n",
    "train_ids, test_ids = train_test_split(\n",
    "    segment_metadata['segment_id'], \n",
    "    test_size=0.30, \n",
    "    random_state=42, \n",
    "    stratify=segment_metadata['label']\n",
    ")\n",
    "\n",
    "# Create the actual DataFrames\n",
    "train_df = df_clean[df_clean['segment_id'].isin(train_ids)].copy()\n",
    "test_df = df_clean[df_clean['segment_id'].isin(test_ids)].copy()\n",
    "\n",
    "# Verification (Counting Unique Flags, NOT Rows)\n",
    "print(f\"Total Segments: {len(segment_metadata)}\")\n",
    "print(f\"Train Segments: {len(train_ids)} ({len(train_ids)/len(segment_metadata):.1%})\")\n",
    "print(f\"Test Segments:  {len(test_ids)} ({len(test_ids)/len(segment_metadata):.1%})\")\n",
    "\n",
    "print(\"\\n--- Train Distribution (Number of Flags) ---\")\n",
    "# Drop duplicates to count 1 flag as 1 item, regardless of how long it is\n",
    "print(train_df.drop_duplicates('segment_id')['label'].value_counts())\n",
    "\n",
    "print(\"\\n--- Test Distribution (Number of Flags) ---\")\n",
    "print(test_df.drop_duplicates('segment_id')['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b29932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PREPARE ONE BATCH OF DATA ---\n",
    "\n",
    "# Settings\n",
    "BATCH_SIZE = 16\n",
    "HIDDEN_SIZE = 12\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Select 16 random unique segment IDs from the training set\n",
    "sample_ids = train_df['segment_id'].drop_duplicates().sample(BATCH_SIZE).values\n",
    "\n",
    "# Dictionary to map text labels to integers (0, 1, 2...)\n",
    "unique_labels = train_df['label'].unique()\n",
    "label_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "for seg_id in sample_ids:\n",
    "    # Get data for this segment\n",
    "    seg_data = train_df[train_df['segment_id'] == seg_id].sort_values('timestamp')\n",
    "    prices = seg_data['close'].values.astype(np.float32)\n",
    "    \n",
    "    # CRITICAL: Normalize each sequence independently (Z-score) \n",
    "    # LSTMs fail if you mix raw prices like 150.00 (AAPL) and 1.05 (EURUSD)\n",
    "    prices = (prices - prices.mean()) / (prices.std() + 1e-6)\n",
    "    \n",
    "    # Convert to tensor [seq_len, 1]\n",
    "    sequences.append(torch.tensor(prices).unsqueeze(1))\n",
    "    \n",
    "    # Get label\n",
    "    label_str = seg_data['label'].iloc[0]\n",
    "    labels.append(label_map[label_str])\n",
    "\n",
    "# Pad sequences to the length of the longest one in the batch\n",
    "# Shape becomes: [Batch, Max_Seq_Len, Features]\n",
    "X_batch = pad_sequence(sequences, batch_first=True).to(DEVICE)\n",
    "y_batch = torch.tensor(labels).long().to(DEVICE)\n",
    "\n",
    "print(f\"Batch Shape: {X_batch.shape}\")  # e.g., [16, 96, 1]\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "# --- 2. DEFINE TINY LSTM ---\n",
    "\n",
    "class TinyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(TinyLSTM, self).__init__()\n",
    "        # Small LSTM: input=1 (close price), hidden=4\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        # Linear layer maps the 12 hidden neurons to the class probabilities\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, seq, feature]\n",
    "        \n",
    "        # Run LSTM\n",
    "        # out: containing output features (h_t) from the last layer of the LSTM for each t\n",
    "        # (h_n, c_n): containing the final hidden state for each element in the batch\n",
    "        out, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        # We only care about the LAST hidden state (the summary of the whole pattern)\n",
    "        # h_n shape: [1, batch, hidden_size] -> squeeze to [batch, hidden_size]\n",
    "        last_hidden = h_n[-1] \n",
    "        \n",
    "        # Classification\n",
    "        logits = self.fc(last_hidden)\n",
    "        return logits\n",
    "\n",
    "# Initialize\n",
    "model = TinyLSTM(input_size=1, hidden_size=HIDDEN_SIZE, num_classes=len(unique_labels)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# --- 3. TRAIN LOOP (Overfitting one batch) ---\n",
    "\n",
    "print(\"\\nStarting Training on Single Batch...\")\n",
    "model.train()\n",
    "\n",
    "for epoch in range(1, 2001):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(X_batch)\n",
    "    loss = criterion(outputs, y_batch)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Check accuracy\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct = (predicted == y_batch).sum().item()\n",
    "    acc = correct / BATCH_SIZE\n",
    "    \n",
    "    # Logging\n",
    "    if epoch % 100 == 0 or acc == 1.0:\n",
    "        print(f\"\\rEpoch {epoch:4d} | Loss: {loss.item():.4f} | Accuracy: {acc:.0%} ({correct}/{BATCH_SIZE})\")\n",
    "    \n",
    "    # Early stopping condition\n",
    "    if acc == 1.0:\n",
    "        print(f\"\\n\\nSuccess! Reached 100% accuracy at epoch {epoch}.\")\n",
    "        break\n",
    "\n",
    "if acc < 1.0:\n",
    "    print(f\"\\n\\nStopped at 2000 epochs. Final Accuracy: {acc:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffecfe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BATCH_SIZE = 32\n",
    "DROPOUT = 0.2        \n",
    "EPOCHS = 2000         \n",
    "LEARNING_RATE = 0.0005\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- CUSTOM DATASET CLASS ---\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df, label_encoder=None):\n",
    "        self.segments = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Group by segment_id to reconstruct the sequences\n",
    "        # We assume df is already sorted by timestamp per segment\n",
    "        grouped = df.groupby('segment_id')\n",
    "        \n",
    "        for _, group in grouped:\n",
    "            # Feature: Close price\n",
    "            prices = group['close'].values.astype(np.float32)\n",
    "            \n",
    "            # Normalize per sequence (Z-score) to make patterns scale-invariant\n",
    "            # This is critical so the model sees the *shape*, not the price level ($10 vs $1000)\n",
    "            if len(prices) > 1 and prices.std() > 0:\n",
    "                prices = (prices - prices.mean()) / prices.std()\n",
    "            else:\n",
    "                prices = (prices - prices.mean()) # Fallback if flat\n",
    "                \n",
    "            self.segments.append(torch.tensor(prices).unsqueeze(1)) # [Seq_Len, 1]\n",
    "            \n",
    "            # Label\n",
    "            label_str = group['label'].iloc[0]\n",
    "            self.labels.append(label_str)\n",
    "            \n",
    "        # Encode labels to integers\n",
    "        if label_encoder is None:\n",
    "            self.le = LabelEncoder()\n",
    "            self.encoded_labels = self.le.fit_transform(self.labels)\n",
    "        else:\n",
    "            self.le = label_encoder\n",
    "            self.encoded_labels = self.le.transform(self.labels)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.segments)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.segments[idx], self.encoded_labels[idx]\n",
    "\n",
    "    def get_num_classes(self):\n",
    "        return len(self.le.classes_)\n",
    "\n",
    "# --- CUSTOM COLLATE FUNCTION ---\n",
    "# Needed because every sequence has a different length\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    \n",
    "    # Get lengths for packing (needed for efficiency)\n",
    "    lengths = torch.tensor([len(s) for s in sequences])\n",
    "    \n",
    "    # Pad sequences to the max length in this specific batch\n",
    "    padded_seqs = pad_sequence(sequences, batch_first=True, padding_value=0.0)\n",
    "    \n",
    "    labels = torch.tensor(labels).long()\n",
    "    \n",
    "    return padded_seqs, labels, lengths\n",
    "\n",
    "# Prepare Data\n",
    "train_dataset = TimeSeriesDataset(train_df)\n",
    "# Use the same label encoder for test set to ensure mapping is consistent\n",
    "test_dataset = TimeSeriesDataset(test_df, label_encoder=train_dataset.le)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Test batches:  {len(test_loader)}\")\n",
    "print(f\"Classes: {train_dataset.le.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4876d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. POSITIONAL ENCODING HELPER ---\n",
    "# Transformers don't have intrinsic recurrence, so we must inject \"order\" information\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Create constant 'pe' matrix with values dependent on pos and i\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        # Register as buffer (not a learnable parameter, but part of state_dict)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [Batch, Seq_Len, d_model]\n",
    "        # Add PE to the input embeddings\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# --- 2. MAIN TRANSFORMER MODEL ---\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, input_size, d_model, nhead, num_layers, num_classes, dropout=0.1):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        \n",
    "        # 1. Input Projection\n",
    "        # Projects your 1 feature (Close price) up to d_model size (e.g. 64)\n",
    "        self.input_net = nn.Linear(input_size, d_model)\n",
    "        \n",
    "        # 2. Positional Encoding\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout=dropout)\n",
    "        \n",
    "        # 3. Transformer Encoder\n",
    "        # batch_first=True ensures input is [Batch, Seq, Feature]\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, \n",
    "                                                   dim_feedforward=d_model*4, \n",
    "                                                   dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # 4. Output Classifier\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "        \n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # x shape: [Batch, Seq_Len, 1]\n",
    "        \n",
    "        # --- SAFETY FIX: Ensure lengths is on correct device ---\n",
    "        lengths = lengths.to(x.device)\n",
    "\n",
    "        # --- A. Create Padding Mask ---\n",
    "        batch_size, max_len, _ = x.shape\n",
    "        range_tensor = torch.arange(max_len, device=x.device).expand(batch_size, max_len)\n",
    "        \n",
    "        # Mask is True where index >= length (padding areas)\n",
    "        mask = range_tensor >= lengths.unsqueeze(1)\n",
    "        \n",
    "        # --- B. Project & Encode ---\n",
    "        x = self.input_net(x) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoder(x)\n",
    "        \n",
    "        # Pass through Transformer\n",
    "        # src_key_padding_mask expects [Batch, Seq_Len]\n",
    "        trans_out = self.transformer_encoder(x, src_key_padding_mask=mask)\n",
    "        \n",
    "        # --- C. Pooling ---\n",
    "        valid_mask = ~mask.unsqueeze(-1) # Invert mask: True = Valid\n",
    "        masked_out = trans_out * valid_mask.float()\n",
    "        \n",
    "        sum_out = masked_out.sum(dim=1)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        lengths_safe = lengths.unsqueeze(1).float()\n",
    "        lengths_safe[lengths_safe == 0] = 1.0 \n",
    "        mean_pool = sum_out / lengths_safe\n",
    "        \n",
    "        # --- D. Classify ---\n",
    "        logits = self.fc(mean_pool)\n",
    "        return logits\n",
    "\n",
    "# --- 3. INITIALIZE ---\n",
    "# Config for Transformer\n",
    "D_MODEL = 32      # Internal dimension (replace hidden_size)\n",
    "NHEAD = 16         # Number of attention heads (must divide D_MODEL)\n",
    "NUM_LAYERS = 2    # Depth\n",
    "\n",
    "model = TimeSeriesTransformer(\n",
    "    input_size=1, \n",
    "    d_model=D_MODEL, \n",
    "    nhead=NHEAD, \n",
    "    num_layers=NUM_LAYERS, \n",
    "    num_classes=train_dataset.get_num_classes(),\n",
    "    dropout=DROPOUT\n",
    ").to(DEVICE)\n",
    "\n",
    "\n",
    "def print_model_summary(model):\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Layer':<25} {'Shape':<20} {'Params':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    total_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad: continue\n",
    "        \n",
    "        # Get shape as a list\n",
    "        shape_list = list(param.shape)\n",
    "        param_count = param.numel()\n",
    "        total_params += param_count\n",
    "        \n",
    "        print(f\"{name:<25} {str(shape_list):<20} {param_count:<10,}\")\n",
    "        \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Total Trainable Params: {total_params:,}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Run this instead of summary()\n",
    "print_model_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fd9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- SETUP TRACKING ---\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'test_loss': [],\n",
    "    'test_acc': []\n",
    "}\n",
    "\n",
    "print(\"\\nStarting Full Training...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # --- TRAINING PHASE ---\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for X_batch, y_batch, lengths in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch, lengths)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        train_total += y_batch.size(0)\n",
    "        train_correct += (predicted == y_batch).sum().item()\n",
    "        \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_acc = train_correct / train_total\n",
    "\n",
    "    # --- VALIDATION/TEST PHASE (Log this every epoch!) ---\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, lengths in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "            output = model(X_batch, lengths)\n",
    "            loss = criterion(output, y_batch)\n",
    "            \n",
    "            total_test_loss += loss.item()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            test_total += y_batch.size(0)\n",
    "            test_correct += (predicted == y_batch).sum().item()\n",
    "            \n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    test_acc = test_correct / test_total\n",
    "\n",
    "    # --- SAVE HISTORY ---\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['test_loss'].append(avg_test_loss)\n",
    "    history['test_acc'].append(test_acc)\n",
    "\n",
    "    # Print Update\n",
    "    print(f\"Epoch {epoch+1:2d}/{EPOCHS} | \"\n",
    "            f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.1%} | \"\n",
    "            f\"Test Loss: {avg_test_loss:.4f} | Test Acc: {test_acc:.1%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05e03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    # --- PLOT LOSS ---\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, history['train_loss'], label='Train Loss')\n",
    "    plt.plot(epochs_range, history['test_loss'], label='Test Loss', linestyle='--')\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "    \n",
    "    # --- PLOT ACCURACY ---\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, history['train_acc'], label='Train Acc', color='green')\n",
    "    plt.plot(epochs_range, history['test_acc'], label='Test Acc', linestyle='--', color='orange')\n",
    "    plt.title('Accuracy Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run the plotter\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb0075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TEST ---\n",
    "print(\"\\n Evaluating on Test Set...\")\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch, lengths in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "        \n",
    "        output = model(X_batch, lengths)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "# --- PLOT CONFUSION MATRIX ---\n",
    "# Calculate the matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=train_dataset.le.classes_))\n",
    "class_names = train_dataset.le.classes_\n",
    "\n",
    "# Plot using Seaborn\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='jet', cbar=False,\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.title('Confusion Matrix', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9912a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map specific indices back to high-level categories (Bullish/Bearish)\n",
    "# train_dataset.le.classes_ holds strings like ['Bearish Normal', 'Bullish Pennant'...]\n",
    "idx_to_class = {i: name for i, name in enumerate(train_dataset.le.classes_)}\n",
    "\n",
    "def get_sentiment(idx):\n",
    "    name = idx_to_class[idx]\n",
    "    if \"Bullish\" in name:\n",
    "        return \"Bullish\"\n",
    "    elif \"Bearish\" in name:\n",
    "        return \"Bearish\"\n",
    "    else:\n",
    "        return \"Unknown\" # Should not happen\n",
    "\n",
    "# Convert your existing predictions/labels to these new categories\n",
    "binary_labels = [get_sentiment(y) for y in all_labels]\n",
    "binary_preds = [get_sentiment(p) for p in all_preds]\n",
    "\n",
    "# Create the 2x2 Confusion Matrix\n",
    "labels_order = [\"Bullish\", \"Bearish\"]\n",
    "cm_binary = confusion_matrix(binary_labels, binary_preds, labels=labels_order)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_binary, annot=True, fmt='d', cmap='RdYlGn', cbar=False,\n",
    "            xticklabels=labels_order, yticklabels=labels_order, annot_kws={\"size\": 16})\n",
    "\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.title('Aggregated Performance: Bullish vs Bearish', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "correct = sum(1 for true, pred in zip(binary_labels, binary_preds) if true == pred)\n",
    "print(f\"Binary Accuracy (Bull vs Bear): {correct / len(binary_labels):.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
